# Entrée du pipeline (pour accueillir un log brut)
input {
    # plugin udp pour écouter sur le protocole
    udp {
        port => 1025
        queue_size => 5000
        type => "nginx"
        tags => ["logs_nginx"]
    }
}

# filtrer
filter {
    # grok découpe le message de log avec un systeme de label
    grok {
        # COMBINEDAPACHELOG est un metalabel qui s"attend à un format de log similaire à celui d"Apache HTTPD
        # GREEDYDATA récupére le "reste" des données
        match => [ "message" , "%{COMBINEDAPACHELOG}+%{GREEDYDATA:extra_fields}"]
        overwrite => [ "message" ]
    }
    # convertion de type
    mutate {
        convert => ["response", "integer"]
        convert => ["bytes", "integer"]
        convert => ["responsetime", "float"]
    }
    # déduit les coordonnées GPS à partir de l"adresse IP
    geoip {
        source => "clientip"
    }
    # conversion / format des dates
    date {
        match => [ "timestamp" , "dd/MMM/YYYY:HH:mm:ss Z" ]
        remove_field => [ "timestamp" ]
    }
    # déduction du navigateur
    useragent {
        source => "agent"
    }
}

# sortie
output {
    # plugin elasticsearch pour écrire directement dans la DB elasticsearch
    elasticsearch {
        hosts => ["elasticsearch:9200"]
        user => "elastic"
        password => "elasticpassword"
        # étiquetage des logs pour faciliter la lecture dans kibana
        index => "flask_%{+YYYY.MM.dd}"
    }
}
